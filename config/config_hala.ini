[run]
# Total batch size, must be divisible by the number of GPUs. //remember to change random crop size**, text file, name
batch_size = 2

# Total iteration step.
iter_steps = 1000000

# The initial learning rate.
initial_learning_rate = 1e-4

# Interval for decaying the learning rate.
decay_steps = 5e4

# The decay rate.
decay_rate = 0.5

# Whether to scale optical flow during downsampling or upsampling.
is_scale = True

# Number of threads for loading input examples.
num_input_threads = 4

# 'beta1' for Adam optimizer: the exponential decay rate for the 1st moment estimates.
beta1 = 0.9

# Number of elements the new dataset will sample.
buffer_size = 250

# Number of gpus to use.
num_gpus = 2

# CPU that guides mul-gpu trainging.
cpu_device = /cpu:0

# How many steps to save checkpoint.
save_checkpoint_interval = 50000

# How many steps to write summary.
write_summary_interval = 200

# How many steps to display log on the terminal.
display_log_interval = 100

# tf.ConfigProto parameters.
allow_soft_placement = True
log_device_placement = False

# L2 weight decay.
regularizer_scale = 1e-4

# save direcory of model, summary, sample and so on, better save it as dataset name.
save_dir = Davis

# Home directpty for checkpoints, summary and sample.
model_name = from_pretrained_480p

# Checkpoints directory, it shall be 'save_dir/model_name/'
checkpoint_dir = checkpoints

# Summary directory, it shall be 'save_dir/model_name/summary_dir'.
summary_dir = summary

# Sample directory, it shall be 'save_dir/model_name/sample_dir'.
sample_dir = sample

# Mode, one of {train, test, generate_fake_flow_occlusion}.
mode = test

# Training mode, one of {no_occlusion, no_self_supervision, self_supervision}.
training_mode = self_supervision

# Bool type, whether restore model from a checkpoint.
is_restore_model = True

# Restoration model name. If is_restore_model=True, restore this checkpoint
restore_model = ./Davis/checkpoints/from_pretrained/model-250000

[dataset]
# Cropping height for training.
crop_h = 576
#crop_h = 360

# Cropping width for training.
crop_w = 768
#crop_w = 640

# Image name list.
# For testing and supervised fine-tuning: 4 columns, first 3 columns are the name of three input images, the last column is the saving image name
# For unsupervised training: 6 columns, first 5 columns are 5 input images, the last column is the saving image name, used for self-supervised training to match flow and occlusion map.

data_list_file = ./dataset/Davis/davis.txt

# Image storage direcory.
#img_dir = /ssd/charig/DAVIS/JPEGImages/Full-Resolution
img_dir = /ssd/charig/DAVIS/JPEGImages/480p

superpixel_dir = /ssd/charig/DAVIS_superpix/training

# Whether to normalize image as input
is_normalize_img = False

# Color space
color_space = lab

[self_supervision]
# Image patch height for self-supervised training.
target_h = 256
	
# Image patch width for self-supervised training.
target_w = 640

# Generated flow and occlusion map directory.
fake_flow_occ_dir = ./Davis/sample/480p

# Generate flow and superpixels on the fly
#on_the_fly = True


[test]
# Restoration model name.
restore_model = ./Davis/checkpoints/from_pretrained_occ_new/model-200000
#restore_model = ./models/Sintel/supervise_finetune
save_dir = ./Davis_self/train

[generate_fake_flow_occlusion]
# Restoration model name.
restore_model = ./Davis/checkpoints/from_pretrained/model-250000
save_dir = ./Davis/sample/480p


