[run]
# Total batch size, must be divisible by the number of GPUs. //remember to change random crop size**, text file, name
batch_size = 4

# Total iteration step.
iter_steps = 1000000

# The initial learning rate.
initial_learning_rate = 1e-4

# Interval for decaying the learning rate.
decay_steps = 5e4

# The decay rate.
decay_rate = 0.5

# Whether to scale optical flow during downsampling or upsampling.
is_scale = True

# Number of threads for loading input examples.
num_input_threads = 4

# 'beta1' for Adam optimizer: the exponential decay rate for the 1st moment estimates.
beta1 = 0.9

# Number of elements the new dataset will sample.
buffer_size = 2500

# Number of gpus to use.
num_gpus = 2

# CPU that guides mul-gpu trainging.
cpu_device = /cpu:0

# How many steps to save checkpoint.
save_checkpoint_interval = 50000

# How many steps to write summary.
write_summary_interval = 200

# How many steps to display log on the terminal.
display_log_interval = 100

# tf.ConfigProto parameters.
allow_soft_placement = True
log_device_placement = False

# L2 weight decay.
regularizer_scale = 1e-4

# save direcory of model, summary, sample and so on, better save it as dataset name.
save_dir = UCF

# Home directpty for checkpoints, summary and sample.
model_name = abs_loss_10_from_pretrained

# Checkpoints directory, it shall be 'save_dir/model_name/'
checkpoint_dir = checkpoints

# Summary directory, it shall be 'save_dir/model_name/summary_dir'.
summary_dir = summary

# Sample directory, it shall be 'save_dir/model_name/sample_dir'.
sample_dir = sample

# Mode, one of {train, test, generate_fake_flow_occlusion}.
mode = test

# Training mode, one of {no_occlusion, no_self_supervision, self_supervision}.
training_mode = no_self_supervision

# Bool type, whether restore model from a checkpoint.
is_restore_model = True

# Restoration model name. If is_restore_model=True, restore this checkpoint
restore_model = ./Sintel/checkpoints/NOC2a/model-175000
#restore_model = ./UCF/checkpoints/rgb_from_pretrained_10/model-700000

[dataset]
# Cropping height for training.
crop_h = 192

# Cropping width for training.
crop_w = 256

# Image name list.
# For testing and supervised fine-tuning: 4 columns, first 3 columns are the name of three input images, the last column is the saving image name
# For unsupervised training: 6 columns, first 5 columns are 5 input images, the last column is the saving image name, used for self-supervised training to match flow and occlusion map.

data_list_file = ./dataset/UCF/ucf_makeup_odd_train.txt
#data_list_file = ./dataset/UCF/10vids_101.txt

# Image storage direcory.
img_dir = /ssd/charig/UCF-101_png
superpixel_dir = ../datasets/KITTI_superpix/training

# Whether to normalize image as input
is_normalize_img = False

# Color space
color_space = lab

[self_supervision]
# Image patch height for self-supervised training.
target_h = 256
	
# Image patch width for self-supervised training.
target_w = 640

# Generated flow and occlusion map directory.
fake_flow_occ_dir = ./KITTI/sample/LabDropLong

# Generate flow and superpixels on the fly
#on_the_fly = True


[test]
# Restoration model name.
restore_model = ./UCF/checkpoints/abs_loss_10_from_pretrained/model-350000
#restore_model = ./models/Sintel/supervise_finetune
save_dir = ./UCF_images3/abs_loss_10_from_pretrained

[generate_fake_flow_occlusion]
# Restoration model name.
restore_model = ./KITTI/checkpoints/LabDropNoc2L/model-350000
save_dir = ./KITTI/sample/LabDropLong



